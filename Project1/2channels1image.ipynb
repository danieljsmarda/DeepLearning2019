{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import dlc_practical_prologue as prologue\n",
    "from BaseNet import *\n",
    "from ConvNet1 import *\n",
    "\n",
    "######################################################\n",
    "### FRAMEWORK FOR INPUT AS ONE IMAGE OF 2 CHANNELS ###\n",
    "\n",
    "# In this framework, the network is trained to directly predict if the first digit is less or equal to the second. It doesn't learn to recognize the digits.\n",
    "\n",
    "nb_classes = 1\n",
    "nb_input_channels = 2\n",
    "\n",
    "mini_batch_size = 1000\n",
    "nb_epochs = 300\n",
    "eta = 0.001\n",
    "\n",
    "\n",
    "# Network is a binary classifier: it simply predicts if the first digit is less than or equal to the second\n",
    "def train_model_2C(model, train_input, train_target, optimizer, mini_batch_size=mini_batch_size,\n",
    "                   criterion=torch.nn.BCEWithLogitsLoss(), nb_epochs=nb_epochs):\n",
    "    train_target = train_target.type(torch.FloatTensor).view(-1, 1)\n",
    "    nb_samples = len(train_input)\n",
    "    \n",
    "    since = time.time()\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for e in range(0, nb_epochs):\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train': model.train()\n",
    "            else: model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for b in range(0, train_input.size(0), mini_batch_size):\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "                    #print(\"output = \", output)\n",
    "                    target = train_target.narrow(0, b, mini_batch_size)\n",
    "                    #print(\"target = \", target)\n",
    "                    \n",
    "                    # the nn.BCEWithLogitsLoss expects\n",
    "                    loss = criterion(output, target)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                running_loss += loss.item() * train_input.size(0)\n",
    "                #print(\"torch.sigmoid = \", torch.sigmoid(output))\n",
    "                output_to_prediction = torch.ge(torch.sigmoid(output), 0.5)\n",
    "                #print(\"output_to_prediction = \", output_to_prediction)\n",
    "                running_corrects += torch.sum(output_to_prediction == target.type(torch.ByteTensor))       \n",
    "\n",
    "            epoch_loss = running_loss / nb_samples\n",
    "            epoch_acc = running_corrects.double() / nb_samples\n",
    "            \n",
    "            if (e % 100 == 99):\n",
    "                print('phase: %s, epoch: %d, loss: %.5f, acc: %.4f' %\n",
    "                      (phase, e+1, epoch_loss, epoch_acc))\n",
    "                \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in %.0f min %.0f s' % (time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val acc: %.4f' % (best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history\n",
    "\n",
    "def test_model_2C(model, test_input, test_target):\n",
    "    model.eval()\n",
    "    print(\"Model in training mode? \", model.training)\n",
    "\n",
    "    # Number of pairs incorrectly identified\n",
    "    test_output = model(test_input)\n",
    "    output_to_prediction = torch.ge(torch.sigmoid(test_output), 0.5).flatten()\n",
    "    \n",
    "    nb_errors_pairs = torch.sum(output_to_prediction != test_target.type(torch.ByteTensor)).item()\n",
    "    print(\"nb_errors_pairs = \", nb_errors_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: train, epoch: 100, loss: 0.18176, acc: 0.9410\n",
      "phase: val, epoch: 100, loss: 0.17862, acc: 0.9410\n",
      "phase: train, epoch: 200, loss: 0.01631, acc: 1.0000\n",
      "phase: val, epoch: 200, loss: 0.01598, acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "    prologue.generate_pair_sets(nb=1000)\n",
    "\n",
    "#model = BaseNet2C(nb_classes)\n",
    "model = ConvNet1_2C(nb_classes)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=eta, momentum=0.95)\n",
    "model, val_acc_history = train_model_2C(model, train_input, train_target, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_2C(model, test_input, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_val_accuracy(model, val_acc_history):\n",
    "    plt.plot(val_acc_history)\n",
    "    plt.xlabel('Number of epochs')\n",
    "    plt.ylabel('Validation accuracy')\n",
    "    plt.title('Validation accuracy on training set with model = ' + model.name)\n",
    "    plt.show()\n",
    "    \n",
    "plot_val_accuracy(model, val_acc_history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
