{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets\n",
    "\n",
    "import dlc_practical_prologue as prologue\n",
    "from BaseNet import *\n",
    "from ConvNet1 import *\n",
    "\n",
    "########################################################\n",
    "### FRAMEWORK FOR INPUT AS TWO SINGLE CHANNEL IMAGES ###\n",
    "\n",
    "# In this framework, the network is first trained to recognize the digits of each image from each pair and with the help of the class labels. To do so, we use the class labels provided and use a CrossEntropyLoss to maximize the response of the correct digit. Once the network can predict the digits, we compare the digits and define if they are a pair or not\n",
    "\n",
    "nb_classes = 10\n",
    "nb_input_channels = 1\n",
    "\n",
    "mini_batch_size = 100\n",
    "nb_epochs = 300\n",
    "eta = 0.001\n",
    "\n",
    "def prep_input_vanilla(train_input):\n",
    "    new_train_input = train_input.view(-1,1,14,14)\n",
    "    return new_train_input\n",
    "\n",
    "def prep_target_vanilla(train_classes):    \n",
    "    train_classes = train_classes.flatten()   \n",
    "    stack = torch.tensor([0.0]*10)    \n",
    "    for i in train_classes:\n",
    "        current = torch.tensor([0.0]*10)\n",
    "        current[i.item()] = 1\n",
    "        stack = torch.cat([stack.view(-1,10),current.view(-1,10)])       \n",
    "    return stack[1:]\n",
    "\n",
    "\n",
    "# Computes the number of errors when predicting with the model passed as parameter and comparing results with the target classes; this corresponds to the task of our network, ie predicting the right digit.\n",
    "def compute_nb_errors(model, input_, target, mini_batch_size=mini_batch_size):\n",
    "    nb_errors = 0  \n",
    "    for b in range(0, input_.size(0), mini_batch_size):\n",
    "        output = model(input_.narrow(0, b, mini_batch_size))\n",
    "        _, target_classes = torch.max(target.narrow(0, b, mini_batch_size), 1)\n",
    "        _, predicted_classes = torch.max(output, 1)\n",
    "        nb_errors += (predicted_classes != target_classes).sum().item()      \n",
    "    return nb_errors\n",
    "\n",
    "# input = 1000x2x14x14: Gets a 2 channels input tensor, predicts a digit for each image of each channel using the model passed as parameter, then compares the pairs channel-wise\n",
    "# output = 1000: 1 if the 2 images are a pair, 0 otherwise\n",
    "def compare_pairs(model, input_):\n",
    "    tensor_a = torch.max(model(input_[:,0,:,:].view(-1,1,14,14)), 1)[1]\n",
    "    tensor_b = torch.max(model(input_[:,1,:,:].view(-1,1,14,14)),1)[1]\n",
    "    return torch.eq(tensor_a, tensor_b)\n",
    "\n",
    "\n",
    "# Network is a classifier: it treats the pairs as 2 images of 1 channel and is trained to predict the digit from the image\n",
    "def train_model_1C(model, train_input, train_classes, mini_batch_size=mini_batch_size,\n",
    "                   criterion=torch.nn.CrossEntropyLoss(), nb_epochs=nb_epochs, eta=eta):\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=eta, momentum=0.95)\n",
    "    \n",
    "    train_input = prep_input_vanilla(train_input)\n",
    "    train_target = prep_target_vanilla(train_classes) # the target are the class labels\n",
    "    \n",
    "    for e in range(0, nb_epochs):\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            target = train_target.narrow(0, b, mini_batch_size)\n",
    "            # the nn.CrossEntropyLoss expects a class index as the target for each value\n",
    "            loss = criterion(output,target.max(1)[1])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if (e % 100 == 99):\n",
    "            print('epoch: %d, loss: %.5f' %\n",
    "                  (e+1, loss.data.item()))\n",
    "            \n",
    "def test_model_1C(model, test_input, test_target, test_classes):\n",
    "    test_input_vanilla = prep_input_vanilla(test_input)\n",
    "    test_classes_target = prep_target_vanilla(test_classes)\n",
    "    \n",
    "    # Number of digits incorrectly identified\n",
    "    nb_errors_digits = compute_nb_errors(model, test_input_vanilla, test_classes_target)\n",
    "    print(\"nb_errors_digits = \", nb_errors_digits)\n",
    "    \n",
    "    # Number of pairs incorrectly identified\n",
    "    test_output_pairs = compare_pairs(model, test_input).type(torch.LongTensor)\n",
    "    nb_errors_pairs = torch.abs(test_output_pairs-test_target).sum().item()\n",
    "    print(\"nb_errors_pairs = \", nb_errors_pairs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 100, loss: 0.00136\n",
      "epoch: 200, loss: 0.00045\n",
      "epoch: 300, loss: 0.00025\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "    prologue.generate_pair_sets(nb=1000)\n",
    "\n",
    "#model = BaseNet(nb_classes)\n",
    "model = ConvNet1(nb_classes)\n",
    "\n",
    "train_model_1C(model, train_input, train_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_errors_digits =  172\n",
      "nb_errors_pairs =  448\n"
     ]
    }
   ],
   "source": [
    "test_model_1C(model, test_input, test_target, test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 462 errors in the training dataset\n",
      "There are 429 errors in the test dataset\n"
     ]
    }
   ],
   "source": [
    "# Computes the number of errors between target and classes\n",
    "def compute_nb_errors_data(set_, target, classes): \n",
    "    is_pair = torch.eq(classes[:,0], classes[:,1]).type(torch.LongTensor)\n",
    "    nb_errors = torch.abs(target-is_pair).sum().item()\n",
    "    print('There are %d errors in the %s dataset' % (nb_errors, set_))\n",
    "    \n",
    "compute_nb_errors_data('training', train_target, train_classes)\n",
    "compute_nb_errors_data('test', test_target, test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
