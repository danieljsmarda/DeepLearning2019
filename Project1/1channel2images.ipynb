{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import dlc_practical_prologue as prologue\n",
    "from BaseNet import *\n",
    "from ConvNet1 import *\n",
    "\n",
    "########################################################\n",
    "### FRAMEWORK FOR INPUT AS TWO SINGLE CHANNEL IMAGES ###\n",
    "\n",
    "# In this framework, the network is first trained to recognize the digits of each image from each pair and with the help of the class labels. To do so, we use the class labels provided and use a CrossEntropyLoss to maximize the response of the correct digit. Once the network can predict the digits, we compare the digits together.\n",
    "\n",
    "nb_classes = 10\n",
    "nb_input_channels = 1\n",
    "\n",
    "mini_batch_size = 100\n",
    "nb_epochs = 300\n",
    "eta = 0.001\n",
    "\n",
    "def prep_input_vanilla(train_input):\n",
    "    new_train_input = train_input.view(-1,1,14,14)\n",
    "    return new_train_input\n",
    "\n",
    "def prep_target_vanilla(train_classes):    \n",
    "    #print(\"train_classes = \", train_classes)\n",
    "    train_classes = train_classes.flatten()   \n",
    "    #print(\"train_classes = \", train_classes)\n",
    "    stack = torch.zeros(10)\n",
    "    #print(\"stack = \", stack)\n",
    "    for i in train_classes:\n",
    "        current = torch.tensor([0.0]*10)\n",
    "        current[i.item()] = 1\n",
    "        stack = torch.cat([stack.view(-1,10),current.view(-1,10)])  \n",
    "        #print(\"stack = \", stack)\n",
    "    print(stack[1:])\n",
    "    return stack[1:]\n",
    "\n",
    "\n",
    "# Computes the number of errors when predicting with the model passed as parameter and comparing results with the target classes; this corresponds to the task of our network, ie predicting the right digit.\n",
    "def compute_nb_errors(model, input_, target, mini_batch_size=mini_batch_size):\n",
    "    nb_errors = 0  \n",
    "    for b in range(0, input_.size(0), mini_batch_size):\n",
    "        output = model(input_.narrow(0, b, mini_batch_size))\n",
    "        _, target_classes = torch.max(target.narrow(0, b, mini_batch_size), 1)\n",
    "        _, predicted_classes = torch.max(output, 1)\n",
    "        nb_errors += (predicted_classes != target_classes).sum().item()      \n",
    "    return nb_errors\n",
    "\n",
    "# input = 1000x2x14x14: Gets a 2 channels input tensor, predicts a digit for each image of each channel using the model passed as parameter, then compares the pairs channel-wise\n",
    "# output = 1000: 1 if the val_a < val_b, 0 otherwise\n",
    "def compare_pairs(model, input_):\n",
    "    tensor_a = torch.max(model(input_[:,0,:,:].view(-1,1,14,14)), 1)[1]\n",
    "    tensor_b = torch.max(model(input_[:,1,:,:].view(-1,1,14,14)),1)[1]\n",
    "    return torch.le(tensor_a, tensor_b)\n",
    "\n",
    "\n",
    "# Network is a classifier: it treats the pairs as 2 images of 1 channel and is trained to predict the digit from the image\n",
    "def train_model_1C(model, train_input, train_classes, mini_batch_size=mini_batch_size,\n",
    "                   criterion=torch.nn.CrossEntropyLoss(), nb_epochs=nb_epochs, eta=eta):\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=eta, momentum=0.95)\n",
    "    \n",
    "    train_input = prep_input_vanilla(train_input)\n",
    "    train_target = prep_target_vanilla(train_classes) # the target are the class labels\n",
    "    \n",
    "    for e in range(0, nb_epochs):\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            target = train_target.narrow(0, b, mini_batch_size)\n",
    "            # the nn.CrossEntropyLoss expects a class index as the target for each value\n",
    "            loss = criterion(output,target.max(1)[1])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if (e % 100 == 99):\n",
    "            print('epoch: %d, loss: %.5f' %\n",
    "                  (e+1, loss.data.item()))\n",
    "            \n",
    "def test_model_1C(model, test_input, test_target, test_classes):\n",
    "    test_input_vanilla = prep_input_vanilla(test_input)\n",
    "    test_classes_target = prep_target_vanilla(test_classes)\n",
    "    \n",
    "    # Number of digits incorrectly identified\n",
    "    nb_errors_digits = compute_nb_errors(model, test_input_vanilla, test_classes_target)\n",
    "    print(\"nb_errors_digits = \", nb_errors_digits)\n",
    "    \n",
    "    # Number of pairs incorrectly identified\n",
    "    test_output_pairs = compare_pairs(model, test_input).type(torch.LongTensor)\n",
    "    nb_errors_pairs = torch.abs(test_output_pairs-test_target).sum().item()\n",
    "    print(\"nb_errors_pairs = \", nb_errors_pairs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d8e9270199cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConvNet1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtrain_model_1C\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-e871811793b4>\u001b[0m in \u001b[0;36mtrain_model_1C\u001b[0;34m(model, train_input, train_classes, mini_batch_size, criterion, nb_epochs, eta)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "    prologue.generate_pair_sets(nb=1000)\n",
    "\n",
    "#model = BaseNet(nb_classes)\n",
    "model = ConvNet1(nb_classes)\n",
    "\n",
    "train_model_1C(model, train_input, train_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_1C(model, test_input, test_target, test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the number of errors between target and classes\n",
    "def compute_nb_errors_data(set_, target, classes): \n",
    "    is_pair = torch.le(classes[:,0], classes[:,1]).type(torch.LongTensor)\n",
    "    nb_errors = torch.abs(target-is_pair).sum().item()\n",
    "    print('There are %d errors in the %s dataset' % (nb_errors, set_))\n",
    "    \n",
    "compute_nb_errors_data('training', train_target, train_classes)\n",
    "compute_nb_errors_data('test', test_target, test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 1])\n",
      "tensor([[5],\n",
      "        [2],\n",
      "        [2],\n",
      "        [1],\n",
      "        [7]])\n",
      "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "nb_digits = 10\n",
    "# Dummy input that HAS to be 2D for the scatter (you can use view(-1,1) if needed)\n",
    "y = torch.LongTensor(batch_size,1).random_() % nb_digits\n",
    "print(y.shape)\n",
    "# One hot encoding buffer that you create out of the loop and just keep reusing\n",
    "y_onehot = torch.FloatTensor(batch_size, nb_digits)\n",
    "\n",
    "# In your for loop\n",
    "y_onehot.zero_()\n",
    "y_onehot.scatter_(1, y, 1)\n",
    "\n",
    "print(y)\n",
    "print(y_onehot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[8, 7],\n",
      "        [1, 4],\n",
      "        [3, 4],\n",
      "        ...,\n",
      "        [7, 4],\n",
      "        [7, 3],\n",
      "        [9, 8]])\n",
      "tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n",
      "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
      "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 1., 0.]])\n",
      "torch.Size([2000, 1])\n",
      "torch.Size([2000, 10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [0., 0., 0.,  ..., 1., 1., 0.],\n",
       "        [0., 1., 0.,  ..., 1., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prep_target_vanillab(train_classes): \n",
    "    y = train_classes.flatten().view(-1, 1)\n",
    "    print(y.shape)\n",
    "    train_onehot = torch.FloatTensor(len(y), nb_classes)\n",
    "    return train_onehot.scatter_(1, y, 1)\n",
    "\n",
    "print(train_classes)\n",
    "prep_target_vanilla(train_classes)\n",
    "prep_target_vanillab(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
