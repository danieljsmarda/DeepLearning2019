{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets\n",
    "\n",
    "import dlc_practical_prologue as prologue\n",
    "from BaseNet import *\n",
    "from ConvNet1 import *\n",
    "\n",
    "########################################################\n",
    "### FRAMEWORK FOR INPUT AS TWO SINGLE CHANNEL IMAGES ###\n",
    "\n",
    "# In this framework, the network is first trained to recognize the digits of each image from each pair and with the help of the class labels. To do so, we use the class labels provided and use a CrossEntropyLoss to maximize the response of the correct digit. Once the network can predict the digits, we compare the digits and define if they are a pair or not\n",
    "\n",
    "nb_classes = 10\n",
    "nb_input_channels = 1\n",
    "\n",
    "mini_batch_size = 100\n",
    "nb_epochs = 300\n",
    "eta = 0.001\n",
    "\n",
    "def prep_input_vanilla(train_input):\n",
    "    new_train_input = train_input.view(-1,1,14,14)\n",
    "    return new_train_input\n",
    "\n",
    "def prep_target_vanilla(train_classes):    \n",
    "    train_classes = train_classes.flatten()   \n",
    "    stack = torch.tensor([0.0]*10)    \n",
    "    for i in train_classes:\n",
    "        current = torch.tensor([0.0]*10)\n",
    "        current[i.item()] = 1\n",
    "        stack = torch.cat([stack.view(-1,10),current.view(-1,10)])       \n",
    "    return stack[1:]\n",
    "\n",
    "\n",
    "# Computes the number of errors when predicting with the model passed as parameter and comparing results with the target classes; this corresponds to the task of our network, ie predicting the right digit.\n",
    "def compute_nb_errors(model, input_, target, mini_batch_size):\n",
    "    nb_errors = 0  \n",
    "    for b in range(0, input_.size(0), mini_batch_size):\n",
    "        output = model(input_.narrow(0, b, mini_batch_size))\n",
    "        _, target_classes = torch.max(target.narrow(0, b, mini_batch_size), 1)\n",
    "        _, predicted_classes = torch.max(outputs, 1)\n",
    "        nb_errors += (predicted_classes != target_classes).sum().item()      \n",
    "    return nb_errors\n",
    "\n",
    "# input = 1000x2x14x14: Gets a 2 channels input tensor, predicts a digit for each image of each channel using the model passed as parameter, then compares the pairs channel-wise\n",
    "# output = 1000: 1 if the 2 images are a pair, 0 otherwise\n",
    "def compare_pairs(model, input_):\n",
    "    tensor_a = torch.max(model(input_[:,0,:,:].view(-1,1,14,14)), 1)[1]\n",
    "    tensor_b = torch.max(model(input_[:,1,:,:].view(-1,1,14,14)),1)[1]\n",
    "    return torch.eq(tensor_a, tensor_b)\n",
    "\n",
    "\n",
    "def train_model_1C(model, train_input, train_classes, mini_batch_size=mini_batch_size,\n",
    "                   criterion=torch.nn.CrossEntropyLoss(), nb_epochs=nb_epochs, eta=eta):\n",
    "    \n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=eta, momentum=0.95)\n",
    "    \n",
    "    train_input = prep_input_vanilla(train_input)\n",
    "    train_target = prep_target_vanilla(train_classes) # the target are the class labels\n",
    "    \n",
    "    for e in range(0, nb_epochs):\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            #print(\"output = \", output.type)\n",
    "            target = train_target.narrow(0, b, mini_batch_size)\n",
    "            # the nn.CrossEntropyLoss expects a class index as the target for each value\n",
    "            loss = criterion(output,target.max(1)[1])\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if (e % 10 == 9):\n",
    "            print('epoch: %d, loss: %.5f' %\n",
    "                  (e+1, loss.data.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss: 0.04437\n",
      "epoch: 20, loss: 0.00349\n",
      "epoch: 30, loss: 0.00189\n",
      "epoch: 40, loss: 0.00135\n",
      "epoch: 50, loss: 0.00105\n",
      "epoch: 60, loss: 0.00086\n",
      "epoch: 70, loss: 0.00073\n",
      "epoch: 80, loss: 0.00063\n",
      "epoch: 90, loss: 0.00055\n",
      "epoch: 100, loss: 0.00049\n",
      "epoch: 110, loss: 0.00044\n",
      "epoch: 120, loss: 0.00040\n",
      "epoch: 130, loss: 0.00037\n",
      "epoch: 140, loss: 0.00034\n",
      "epoch: 150, loss: 0.00032\n",
      "epoch: 160, loss: 0.00030\n",
      "epoch: 170, loss: 0.00028\n",
      "epoch: 180, loss: 0.00026\n",
      "epoch: 190, loss: 0.00025\n",
      "epoch: 200, loss: 0.00023\n",
      "epoch: 210, loss: 0.00022\n",
      "epoch: 220, loss: 0.00021\n",
      "epoch: 230, loss: 0.00020\n",
      "epoch: 240, loss: 0.00019\n",
      "epoch: 250, loss: 0.00018\n",
      "epoch: 260, loss: 0.00017\n",
      "epoch: 270, loss: 0.00017\n",
      "epoch: 280, loss: 0.00016\n",
      "epoch: 290, loss: 0.00015\n",
      "epoch: 300, loss: 0.00015\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "    prologue.generate_pair_sets(nb=1000)\n",
    "\n",
    "model = BaseNet(nb_classes)\n",
    "#model = ConvNet1(nb_classes)\n",
    "\n",
    "train_model_1C(model, train_input, train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
