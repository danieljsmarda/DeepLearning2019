{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import dlc_practical_prologue as prologue\n",
    "from BaseNet import *\n",
    "from ConvNet1 import *\n",
    "\n",
    "########################################################\n",
    "### FRAMEWORK FOR INPUT AS TWO SINGLE CHANNEL IMAGES ###\n",
    "\n",
    "# In this framework, the network is first trained to recognize the digits of each image from each pair and with the help of the class labels. To do so, we use the class labels provided and use a CrossEntropyLoss to maximize the response of the correct digit. Once the network can predict the digits, we compare the digits together.\n",
    "\n",
    "nb_classes = 10\n",
    "nb_input_channels = 1\n",
    "\n",
    "mini_batch_size = 1000\n",
    "nb_epochs = 300\n",
    "eta = 0.001\n",
    "\n",
    "def prep_input_vanilla(train_input):\n",
    "    new_train_input = train_input.view(-1,1,14,14)\n",
    "    return new_train_input\n",
    "\n",
    "# One-hot encoding for train_classes\n",
    "def prep_target_vanilla(train_classes): \n",
    "    y = train_classes.flatten().view(-1, 1)\n",
    "    #print(\"y = \", y)\n",
    "    train_onehot = torch.FloatTensor(len(y), nb_classes)\n",
    "    #print(\"one_hot = \", train_onehot.scatter_(1, y, 1))\n",
    "    return train_onehot.scatter_(1, y, 1)\n",
    "\n",
    "\n",
    "# Computes the number of errors when predicting with the model passed as parameter and comparing results with the target classes; this corresponds to the task of our network, ie predicting the right digit.\n",
    "def compute_nb_errors(model, input_, target, mini_batch_size=mini_batch_size):\n",
    "    nb_errors = 0  \n",
    "    for b in range(0, input_.size(0), mini_batch_size):\n",
    "        output = model(input_.narrow(0, b, mini_batch_size))\n",
    "        _, target_classes = torch.max(target.narrow(0, b, mini_batch_size), 1)\n",
    "        _, predicted_classes = torch.max(output, 1)\n",
    "        nb_errors += (predicted_classes != target_classes).sum().item()      \n",
    "    return nb_errors\n",
    "\n",
    "# input = 1000x2x14x14: Gets a 2 channels input tensor, predicts a digit for each image of each channel using the model passed as parameter, then compares the pairs channel-wise\n",
    "# output = 1000: 1 if the val_a < val_b, 0 otherwise\n",
    "def compare_pairs(model, input_):\n",
    "    tensor_a = torch.max(model(input_[:,0,:,:].view(-1,1,14,14)), 1)[1]\n",
    "    tensor_b = torch.max(model(input_[:,1,:,:].view(-1,1,14,14)),1)[1]\n",
    "    return torch.le(tensor_a, tensor_b)\n",
    "\n",
    "\n",
    "# Network is a classifier: it treats the pairs as 2 images of 1 channel and is trained to predict the digit from the image\n",
    "def train_model_1C(model, train_input, train_classes, optimizer, mini_batch_size=mini_batch_size,\n",
    "                   criterion=torch.nn.CrossEntropyLoss(), nb_epochs=nb_epochs):\n",
    "    train_input = prep_input_vanilla(train_input)\n",
    "    train_target = train_classes.flatten() # the target are the class labels \n",
    "    nb_samples = len(train_input)\n",
    "    \n",
    "    since = time.time()\n",
    "    val_acc_history = []\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for e in range(0, nb_epochs):\n",
    "        \n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train': model.train()\n",
    "            else: model.eval()\n",
    "                \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            \n",
    "            for b in range(0, train_input.size(0), mini_batch_size):\n",
    "                optimizer.zero_grad()\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "                    target = train_target.narrow(0, b, mini_batch_size)\n",
    "                    \n",
    "                    # the nn.CrossEntropyLoss expects a class index as the target for each value\n",
    "                    loss = criterion(output, target)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                running_loss += loss.item() * train_input.size(0)\n",
    "                running_corrects += torch.sum(torch.max(output, 1)[1] == target)       \n",
    "\n",
    "            epoch_loss = running_loss / nb_samples\n",
    "            epoch_acc = running_corrects.double() / nb_samples\n",
    "            \n",
    "            if (e % 100 == 99):\n",
    "                print('phase: %s, epoch: %d, loss: %.5f, acc: %.4f' %\n",
    "                      (phase, e+1, epoch_loss, epoch_acc))\n",
    "                \n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "            if phase == 'val':\n",
    "                val_acc_history.append(epoch_acc)\n",
    "                \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in %.0f min %.0f s' % (time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val acc: %.4f' % (best_acc))\n",
    "    \n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, val_acc_history\n",
    "            \n",
    "def test_model_1C(model, test_input, test_target, test_classes):\n",
    "    test_input_vanilla = prep_input_vanilla(test_input)\n",
    "    test_classes_target = prep_target_vanilla(test_classes)\n",
    "    \n",
    "    # Number of digits incorrectly identified\n",
    "    nb_errors_digits = compute_nb_errors(model, test_input_vanilla, test_classes_target)\n",
    "    print(\"nb_errors_digits = \", nb_errors_digits)\n",
    "    \n",
    "    # Number of pairs incorrectly identified\n",
    "    test_output_pairs = compare_pairs(model, test_input).type(torch.LongTensor)\n",
    "    nb_errors_pairs = torch.abs(test_output_pairs-test_target).sum().item()\n",
    "    print(\"nb_errors_pairs = \", nb_errors_pairs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phase: train, epoch: 100, loss: 1.44493, acc: 0.7915\n",
      "phase: val, epoch: 100, loss: 1.42741, acc: 0.7945\n"
     ]
    }
   ],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "    prologue.generate_pair_sets(nb=1000)\n",
    "\n",
    "#model = BaseNet(nb_classes)\n",
    "model = ConvNet1(nb_classes)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=eta, momentum=0.95)\n",
    "train_model_1C(model, train_input, train_classes, optimizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_1C(model, test_input, test_target, test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes the number of errors between target and classes\n",
    "def compute_nb_errors_data(set_, target, classes): \n",
    "    is_pair = torch.le(classes[:,0], classes[:,1]).type(torch.LongTensor)\n",
    "    nb_errors = torch.abs(target-is_pair).sum().item()\n",
    "    print('There are %d errors in the %s dataset' % (nb_errors, set_))\n",
    "    \n",
    "compute_nb_errors_data('training', train_target, train_classes)\n",
    "compute_nb_errors_data('test', test_target, test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
