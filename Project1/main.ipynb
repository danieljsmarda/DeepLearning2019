{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import models and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torch\n",
    "import dlc_practical_prologue as prologue\n",
    "\n",
    "# Import all models\n",
    "from BaseNet import *\n",
    "from ConvNet1 import *\n",
    "from NetSharing1 import *\n",
    "\n",
    "mini_batch_size = 1000\n",
    "nb_epochs = 300\n",
    "nb_runs = 2\n",
    "eta = 0.001\n",
    "\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "    prologue.generate_pair_sets(nb=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1channel2images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 1channel2images framework, nb_classes =  10\n",
      "phase: train, epoch: 100, loss: 1.44493, acc: 0.7915\n",
      "phase: val, epoch: 100, loss: 1.42741, acc: 0.7945\n",
      "phase: train, epoch: 200, loss: 0.27240, acc: 0.9605\n",
      "phase: val, epoch: 200, loss: 0.26991, acc: 0.9610\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import _1channel2images\n",
    "reload(_1channel2images)\n",
    "from _1channel2images import *\n",
    "\n",
    "print(\"Working with 1channel2images framework, nb_classes = \", nb_classes)\n",
    "\n",
    "#model = BaseNet1C(nb_classes)\n",
    "model_1C = ConvNet1_1C(nb_classes)\n",
    "optimizer_1C = torch.optim.SGD(model_1C.parameters(), lr=eta, momentum=0.95)\n",
    "test_results_1C = multiple_training_runs(model_1C, 2, optimizer_1C, train_input, train_classes,\n",
    "                                      test_input, test_target, test_classes, mini_batch_size, nb_epochs)\n",
    "write_to_csv('1channel2images.csv', model_1C, test_results_1C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just for visualization of our results but it will have to be taken away for the report \n",
    "# since we can't use any additional libraries\n",
    "import pandas as pd\n",
    "\n",
    "print(test_results_1C)\n",
    "write_to_csv('1channel2images.csv', model_1C, test_results_1C)\n",
    "data = pd.read_csv('1channel2images.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2channels1image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _2channels1image\n",
    "reload(_2channels1image)\n",
    "from _2channels1image import *\n",
    "\n",
    "print(\"Working with 2channels1image framework, nb_classes = \", nb_classes)\n",
    "\n",
    "model_2C = ConvNet1_2C(nb_classes)\n",
    "optimizer_2C = torch.optim.SGD(model_2C.parameters(), lr=0.00001, momentum=0.95)  \n",
    "test_results_2C = multiple_training_runs(model_2C, 2, optimizer_2C, train_input, train_target,\n",
    "                           test_input, test_target, test_classes, mini_batch_size, nb_epochs)\n",
    "write_to_csv('2channels1image.csv', model_2C, test_results_2C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_results_2C)\n",
    "write_to_csv('2channels1image.csv', model_2C, test_results_2C)\n",
    "data = pd.read_csv('2channels1image.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import weight_sharing\n",
    "reload(weight_sharing)\n",
    "from weight_sharing import *\n",
    "\n",
    "print(\"Working with weight_sharing framework\")\n",
    "\n",
    "model_ws = NetSharing1()\n",
    "optimizer_ws = torch.optim.SGD(model_ws.parameters(), lr=0.00001, momentum=0.95)  \n",
    "test_results_ws = multiple_training_runs(model_ws, nb_runs, optimizer_ws, train_input, train_target,\n",
    "                           test_input, test_target, mini_batch_size, nb_epochs)\n",
    "write_to_csv('weightsharing.csv', model_ws, test_results_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_results_ws)\n",
    "write_to_csv('weightsharing.csv', model_ws, test_results_ws)\n",
    "data = pd.read_csv('weightsharing.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
