{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import models and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torch\n",
    "import dlc_practical_prologue as prologue\n",
    "\n",
    "# Import all models\n",
    "from BaseNet import *\n",
    "from ConvNet1 import *\n",
    "from NetSharing1 import *\n",
    "\n",
    "mini_batch_size = 1000\n",
    "nb_epochs = 300\n",
    "nb_runs = 2\n",
    "eta = 0.001\n",
    "\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "    prologue.generate_pair_sets(nb=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1channel2images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 1channel2images framework, nb_classes =  10\n",
      "phase: train, epoch: 100, loss: 1.44493, acc: 0.7915\n",
      "phase: val, epoch: 100, loss: 1.42741, acc: 0.7945\n",
      "phase: train, epoch: 200, loss: 0.27240, acc: 0.9605\n",
      "phase: val, epoch: 200, loss: 0.26991, acc: 0.9610\n",
      "phase: train, epoch: 300, loss: 0.09784, acc: 0.9925\n",
      "phase: val, epoch: 300, loss: 0.09711, acc: 0.9925\n",
      "Training complete in 7 min 40 s\n",
      "Best val acc: 0.9925\n",
      "phase: train, epoch: 100, loss: 1.36705, acc: 0.8015\n",
      "phase: val, epoch: 100, loss: 1.35128, acc: 0.8050\n",
      "phase: train, epoch: 200, loss: 0.24406, acc: 0.9655\n",
      "phase: val, epoch: 200, loss: 0.24171, acc: 0.9655\n",
      "phase: train, epoch: 300, loss: 0.08303, acc: 0.9935\n",
      "phase: val, epoch: 300, loss: 0.08235, acc: 0.9945\n",
      "Training complete in 6 min 54 s\n",
      "Best val acc: 0.9945\n",
      "Overwriting file\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import _1channel2images\n",
    "reload(_1channel2images)\n",
    "from _1channel2images import *\n",
    "\n",
    "print(\"Working with 1channel2images framework, nb_classes = \", nb_classes)\n",
    "\n",
    "#model = BaseNet1C(nb_classes)\n",
    "model_1C = ConvNet1_1C(nb_classes)\n",
    "optimizer_1C = torch.optim.SGD(model_1C.parameters(), lr=eta, momentum=0.95)\n",
    "test_results_1C = multiple_training_runs(model_1C, 2, optimizer_1C, train_input, train_classes,\n",
    "                                      test_input, test_target, test_classes, mini_batch_size, nb_epochs)\n",
    "write_to_csv('1channel2images.csv', model_1C, test_results_1C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(436.9516521692276, 32.183775053303684, 0.8707499999999999, 0.0017677669529664096, 0.912, 0.004242640687119289)\n",
      "Overwriting file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Number of parameters</th>\n",
       "      <th>Training time</th>\n",
       "      <th>Mean digits accuracy (test set)</th>\n",
       "      <th>Std digits accuracy</th>\n",
       "      <th>Mean accuracy (test set)</th>\n",
       "      <th>Std accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ConvNet1_1C</td>\n",
       "      <td>72226</td>\n",
       "      <td>436.95</td>\n",
       "      <td>0.8707</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Number of parameters  Training time  \\\n",
       "0  ConvNet1_1C                 72226         436.95   \n",
       "\n",
       "   Mean digits accuracy (test set)  Std digits accuracy  \\\n",
       "0                           0.8707               0.0018   \n",
       "\n",
       "   Mean accuracy (test set)  Std accuracy  \n",
       "0                     0.912        0.0042  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is just for visualization of our results but it will have to be taken away for the report \n",
    "# since we can't use any additional libraries\n",
    "import pandas as pd\n",
    "\n",
    "print(test_results_1C)\n",
    "write_to_csv('1channel2images.csv', model_1C, test_results_1C)\n",
    "data = pd.read_csv('1channel2images.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2channels1image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 2channels1image framework, nb_classes =  1\n",
      "phase: train, epoch: 100, loss: 0.64736, acc: 0.6630\n",
      "phase: val, epoch: 100, loss: 0.64125, acc: 0.6690\n",
      "phase: train, epoch: 200, loss: 0.54879, acc: 0.7190\n",
      "phase: val, epoch: 200, loss: 0.54821, acc: 0.7200\n",
      "phase: train, epoch: 300, loss: 0.49894, acc: 0.7560\n",
      "phase: val, epoch: 300, loss: 0.49851, acc: 0.7560\n",
      "Training complete in 1 min 26 s\n",
      "Best val acc: 0.7560\n",
      "phase: train, epoch: 100, loss: 0.63745, acc: 0.6730\n",
      "phase: val, epoch: 100, loss: 0.63124, acc: 0.6760\n",
      "phase: train, epoch: 200, loss: 0.53927, acc: 0.7260\n",
      "phase: val, epoch: 200, loss: 0.53869, acc: 0.7280\n",
      "phase: train, epoch: 300, loss: 0.48994, acc: 0.7560\n",
      "phase: val, epoch: 300, loss: 0.48954, acc: 0.7560\n",
      "Training complete in 1 min 37 s\n",
      "Best val acc: 0.7560\n"
     ]
    }
   ],
   "source": [
    "import _2channels1image\n",
    "reload(_2channels1image)\n",
    "from _2channels1image import *\n",
    "\n",
    "print(\"Working with 2channels1image framework, nb_classes = \", nb_classes)\n",
    "\n",
    "model_2C = ConvNet1_2C(nb_classes)\n",
    "optimizer_2C = torch.optim.SGD(model_2C.parameters(), lr=0.00001, momentum=0.95)  \n",
    "test_results_2C = multiple_training_runs(model_2C, 2, optimizer_2C, train_input, train_target,\n",
    "                           test_input, test_target, mini_batch_size, nb_epochs)\n",
    "write_to_csv('2channels1image.csv', model_2C, test_results_2C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91.07980024814606, 7.846400394134911, 0.7045, 0.002121320343559566)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Number of parameters</th>\n",
       "      <th>Training time</th>\n",
       "      <th>Mean accuracy (test set)</th>\n",
       "      <th>Std accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ConvNet1_2C</td>\n",
       "      <td>70705</td>\n",
       "      <td>91.08</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Number of parameters  Training time  Mean accuracy (test set)  \\\n",
       "0  ConvNet1_2C                 70705          91.08                    0.7045   \n",
       "\n",
       "   Std accuracy  \n",
       "0        0.0021  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_results_2C)\n",
    "write_to_csv('2channels1image.csv', model_2C, test_results_2C)\n",
    "data = pd.read_csv('2channels1image.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with weight_sharing framework\n",
      "phase: train, epoch: 100, loss: 0.50720, acc: 0.8010\n",
      "phase: val, epoch: 100, loss: 0.49663, acc: 0.7980\n",
      "phase: train, epoch: 200, loss: 0.38888, acc: 0.8340\n",
      "phase: val, epoch: 200, loss: 0.38819, acc: 0.8340\n",
      "phase: train, epoch: 300, loss: 0.33217, acc: 0.8570\n",
      "phase: val, epoch: 300, loss: 0.33173, acc: 0.8570\n",
      "Training complete in 2 min 34 s\n",
      "Best val acc: 0.8570\n",
      "phase: train, epoch: 100, loss: 0.49602, acc: 0.8040\n",
      "phase: val, epoch: 100, loss: 0.48593, acc: 0.8000\n",
      "phase: train, epoch: 200, loss: 0.37968, acc: 0.8370\n",
      "phase: val, epoch: 200, loss: 0.37899, acc: 0.8370\n",
      "phase: train, epoch: 300, loss: 0.32445, acc: 0.8610\n",
      "phase: val, epoch: 300, loss: 0.32403, acc: 0.8610\n",
      "Training complete in 2 min 40 s\n",
      "Best val acc: 0.8610\n"
     ]
    }
   ],
   "source": [
    "import weight_sharing\n",
    "reload(weight_sharing)\n",
    "from weight_sharing import *\n",
    "\n",
    "print(\"Working with weight_sharing framework\")\n",
    "\n",
    "model_ws = NetSharing1()\n",
    "optimizer_ws = torch.optim.SGD(model_ws.parameters(), lr=0.00001, momentum=0.95)  \n",
    "test_results_ws = multiple_training_runs(model_ws, nb_runs, optimizer_ws, train_input, train_target,\n",
    "                           test_input, test_target, mini_batch_size, nb_epochs)\n",
    "write_to_csv('weightsharing.csv', model_ws, test_results_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_results_ws)\n",
    "write_to_csv('weightsharing.csv', model_ws, test_results_ws)\n",
    "data = pd.read_csv('weightsharing.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
