{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import models and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/torchvision/datasets/mnist.py:53: UserWarning: train_data has been renamed data\n",
      "  warnings.warn(\"train_data has been renamed data\")\n",
      "/usr/local/lib/python3.7/site-packages/torchvision/datasets/mnist.py:43: UserWarning: train_labels has been renamed targets\n",
      "  warnings.warn(\"train_labels has been renamed targets\")\n",
      "/usr/local/lib/python3.7/site-packages/torchvision/datasets/mnist.py:58: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/usr/local/lib/python3.7/site-packages/torchvision/datasets/mnist.py:48: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets\n",
    "import torch\n",
    "import dlc_practical_prologue as prologue\n",
    "\n",
    "# Import all models\n",
    "from BaseNet import *\n",
    "from ConvNet1 import *\n",
    "#from NetSharing import *\n",
    "\n",
    "mini_batch_size = 1000\n",
    "nb_epochs = 300\n",
    "nb_runs = 2\n",
    "eta = 0.001\n",
    "\n",
    "train_input, train_target, train_classes, test_input, test_target, test_classes = \\\n",
    "    prologue.generate_pair_sets(nb=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_classes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [3],\n",
       "        [5]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.narrow(1,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2],\n",
       "        [4],\n",
       "        [6]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.narrow(1,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1channel2images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 1channel2images framework, nb_classes =  10\n",
      "phase: train, epoch: 100, loss: 1.44493, acc: 0.7915\n",
      "phase: val, epoch: 100, loss: 1.42741, acc: 0.7945\n",
      "phase: train, epoch: 200, loss: 0.27240, acc: 0.9605\n",
      "phase: val, epoch: 200, loss: 0.26991, acc: 0.9610\n",
      "phase: train, epoch: 300, loss: 0.09784, acc: 0.9925\n",
      "phase: val, epoch: 300, loss: 0.09711, acc: 0.9925\n",
      "Training complete in 7 min 40 s\n",
      "Best val acc: 0.9925\n",
      "phase: train, epoch: 100, loss: 1.36705, acc: 0.8015\n",
      "phase: val, epoch: 100, loss: 1.35128, acc: 0.8050\n",
      "phase: train, epoch: 200, loss: 0.24406, acc: 0.9655\n",
      "phase: val, epoch: 200, loss: 0.24171, acc: 0.9655\n",
      "phase: train, epoch: 300, loss: 0.08303, acc: 0.9935\n",
      "phase: val, epoch: 300, loss: 0.08235, acc: 0.9945\n",
      "Training complete in 6 min 54 s\n",
      "Best val acc: 0.9945\n",
      "Overwriting file\n"
     ]
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import _1channel2images\n",
    "reload(_1channel2images)\n",
    "from _1channel2images import *\n",
    "\n",
    "print(\"Working with 1channel2images framework, nb_classes = \", nb_classes)\n",
    "\n",
    "#model = BaseNet1C(nb_classes)\n",
    "model_1C = ConvNet1_1C(nb_classes)\n",
    "optimizer_1C = torch.optim.SGD(model_1C.parameters(), lr=eta, momentum=0.95)\n",
    "test_results_1C = multiple_training_runs(model_1C, 2, optimizer_1C, train_input, train_classes,\n",
    "                                      test_input, test_target, test_classes, mini_batch_size, nb_epochs)\n",
    "write_to_csv('1channel2images.csv', model_1C, test_results_1C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(436.9516521692276, 32.183775053303684, 0.8707499999999999, 0.0017677669529664096, 0.912, 0.004242640687119289)\n",
      "Overwriting file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Number of parameters</th>\n",
       "      <th>Training time</th>\n",
       "      <th>Mean digits accuracy (test set)</th>\n",
       "      <th>Std digits accuracy</th>\n",
       "      <th>Mean accuracy (test set)</th>\n",
       "      <th>Std accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ConvNet1_1C</td>\n",
       "      <td>72226</td>\n",
       "      <td>436.95</td>\n",
       "      <td>0.8707</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.0042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Number of parameters  Training time  \\\n",
       "0  ConvNet1_1C                 72226         436.95   \n",
       "\n",
       "   Mean digits accuracy (test set)  Std digits accuracy  \\\n",
       "0                           0.8707               0.0018   \n",
       "\n",
       "   Mean accuracy (test set)  Std accuracy  \n",
       "0                     0.912        0.0042  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is just for visualization of our results but it will have to be taken away for the report \n",
    "# since we can't use any additional libraries\n",
    "import pandas as pd\n",
    "\n",
    "print(test_results_1C)\n",
    "write_to_csv('1channel2images.csv', model_1C, test_results_1C)\n",
    "data = pd.read_csv('1channel2images.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2channels1image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with 2channels1image framework, nb_classes =  1\n",
      "phase: train, epoch: 100, loss: 0.64736, acc: 0.6630\n",
      "phase: val, epoch: 100, loss: 0.64125, acc: 0.6690\n",
      "phase: train, epoch: 200, loss: 0.54879, acc: 0.7190\n",
      "phase: val, epoch: 200, loss: 0.54821, acc: 0.7200\n",
      "phase: train, epoch: 300, loss: 0.49894, acc: 0.7560\n",
      "phase: val, epoch: 300, loss: 0.49851, acc: 0.7560\n",
      "Training complete in 1 min 26 s\n",
      "Best val acc: 0.7560\n",
      "phase: train, epoch: 100, loss: 0.63745, acc: 0.6730\n",
      "phase: val, epoch: 100, loss: 0.63124, acc: 0.6760\n",
      "phase: train, epoch: 200, loss: 0.53927, acc: 0.7260\n",
      "phase: val, epoch: 200, loss: 0.53869, acc: 0.7280\n",
      "phase: train, epoch: 300, loss: 0.48994, acc: 0.7560\n",
      "phase: val, epoch: 300, loss: 0.48954, acc: 0.7560\n",
      "Training complete in 1 min 37 s\n",
      "Best val acc: 0.7560\n"
     ]
    }
   ],
   "source": [
    "import _2channels1image\n",
    "reload(_2channels1image)\n",
    "from _2channels1image import *\n",
    "\n",
    "print(\"Working with 2channels1image framework, nb_classes = \", nb_classes)\n",
    "\n",
    "model_2C = ConvNet1_2C(nb_classes)\n",
    "optimizer_2C = torch.optim.SGD(model_2C.parameters(), lr=0.00001, momentum=0.95)  \n",
    "test_results_2C = multiple_training_runs(model_2C, 2, optimizer_2C, train_input, train_target,\n",
    "                           test_input, test_target, mini_batch_size, nb_epochs)\n",
    "write_to_csv('2channels1image.csv', model_2C, test_results_2C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91.07980024814606, 7.846400394134911, 0.7045, 0.002121320343559566)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Number of parameters</th>\n",
       "      <th>Training time</th>\n",
       "      <th>Mean accuracy (test set)</th>\n",
       "      <th>Std accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ConvNet1_2C</td>\n",
       "      <td>70705</td>\n",
       "      <td>91.08</td>\n",
       "      <td>0.7045</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Number of parameters  Training time  Mean accuracy (test set)  \\\n",
       "0  ConvNet1_2C                 70705          91.08                    0.7045   \n",
       "\n",
       "   Std accuracy  \n",
       "0        0.0021  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_results_2C)\n",
    "write_to_csv('2channels1image.csv', model_2C, test_results_2C)\n",
    "data = pd.read_csv('2channels1image.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with weight_sharing framework\n",
      "phase: train, epoch: 100, loss: 0.50720, acc: 0.8010\n",
      "phase: val, epoch: 100, loss: 0.49663, acc: 0.7980\n",
      "phase: train, epoch: 200, loss: 0.38888, acc: 0.8340\n",
      "phase: val, epoch: 200, loss: 0.38819, acc: 0.8340\n",
      "phase: train, epoch: 300, loss: 0.33217, acc: 0.8570\n",
      "phase: val, epoch: 300, loss: 0.33173, acc: 0.8570\n",
      "Training complete in 2 min 34 s\n",
      "Best val acc: 0.8570\n",
      "phase: train, epoch: 100, loss: 0.49602, acc: 0.8040\n",
      "phase: val, epoch: 100, loss: 0.48593, acc: 0.8000\n",
      "phase: train, epoch: 200, loss: 0.37968, acc: 0.8370\n",
      "phase: val, epoch: 200, loss: 0.37899, acc: 0.8370\n",
      "phase: train, epoch: 300, loss: 0.32445, acc: 0.8610\n",
      "phase: val, epoch: 300, loss: 0.32403, acc: 0.8610\n",
      "Training complete in 2 min 40 s\n",
      "Best val acc: 0.8610\n"
     ]
    }
   ],
   "source": [
    "import weight_sharing\n",
    "reload(weight_sharing)\n",
    "from weight_sharing import *\n",
    "\n",
    "print(\"Working with weight_sharing framework\")\n",
    "\n",
    "model_ws = NetSharing1()\n",
    "optimizer_ws = torch.optim.SGD(model_ws.parameters(), lr=0.00001, momentum=0.95)  \n",
    "test_results_ws = multiple_training_runs(model_ws, nb_runs, optimizer_ws, train_input, train_target,\n",
    "                           test_input, test_target, mini_batch_size, nb_epochs)\n",
    "write_to_csv('weightsharing.csv', model_ws, test_results_ws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(157.0215289592743, 4.446958156281669, 0.768, 0.0014142135623730963)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Number of parameters</th>\n",
       "      <th>Training time</th>\n",
       "      <th>Mean accuracy (test set)</th>\n",
       "      <th>Std accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NetSharing1</td>\n",
       "      <td>70318</td>\n",
       "      <td>157.02</td>\n",
       "      <td>0.768</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Model  Number of parameters  Training time  Mean accuracy (test set)  \\\n",
       "0  NetSharing1                 70318         157.02                     0.768   \n",
       "\n",
       "   Std accuracy  \n",
       "0        0.0014  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_results_ws)\n",
    "write_to_csv('weightsharing.csv', model_ws, test_results_ws)\n",
    "data = pd.read_csv('weightsharing.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with auxiliary losses framework\n",
      "train_input.shape =  torch.Size([1000, 2, 14, 14])\n",
      "train_classes.shape =  torch.Size([1000, 2])\n",
      "train_classes[0] =  tensor([9, 3])\n",
      "train_target.shape =  torch.Size([1000, 1])\n",
      "phase: train, epoch: 100, loss: 2.20260, acc: 0.6860\n",
      "phase: val, epoch: 100, loss: 2.19653, acc: 0.6870\n",
      "phase: train, epoch: 200, loss: 1.93689, acc: 0.7290\n",
      "phase: val, epoch: 200, loss: 1.93538, acc: 0.7290\n",
      "phase: train, epoch: 300, loss: 1.82158, acc: 0.7450\n",
      "phase: val, epoch: 300, loss: 1.82069, acc: 0.7460\n",
      "Training complete in 2 min 35 s\n",
      "Best val acc: 0.7460\n",
      "output_to_pred =  tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 1], dtype=torch.uint8)\n",
      "target =  tensor([1, 0, 0, 1, 0, 1, 0, 1, 1, 1])\n",
      "nb_errors =  307\n",
      "acc_pairs =  0.6930000000000001\n",
      "train_input.shape =  torch.Size([1000, 2, 14, 14])\n",
      "train_classes.shape =  torch.Size([1000, 2])\n",
      "train_classes[0] =  tensor([9, 3])\n",
      "train_target.shape =  torch.Size([1000, 1])\n",
      "phase: train, epoch: 100, loss: 2.17891, acc: 0.6870\n",
      "phase: val, epoch: 100, loss: 2.17294, acc: 0.6880\n",
      "phase: train, epoch: 200, loss: 1.91750, acc: 0.7320\n",
      "phase: val, epoch: 200, loss: 1.91603, acc: 0.7330\n",
      "phase: train, epoch: 300, loss: 1.80596, acc: 0.7460\n",
      "phase: val, epoch: 300, loss: 1.80511, acc: 0.7460\n",
      "Training complete in 2 min 47 s\n",
      "Best val acc: 0.7470\n",
      "output_to_pred =  tensor([1, 0, 0, 1, 0, 1, 0, 1, 0, 1], dtype=torch.uint8)\n",
      "target =  tensor([1, 0, 0, 1, 0, 1, 0, 1, 1, 1])\n",
      "nb_errors =  310\n",
      "acc_pairs =  0.69\n",
      "Overwriting file\n"
     ]
    }
   ],
   "source": [
    "import auxiliary_losses\n",
    "reload(auxiliary_losses)\n",
    "from auxiliary_losses import *\n",
    "import Incept1\n",
    "reload(Incept1)\n",
    "from Incept1 import *\n",
    "nb_epochs = 300\n",
    "print(\"Working with auxiliary losses framework\")\n",
    "\n",
    "model_aux = Incept1()\n",
    "optimizer_aux = torch.optim.SGD(model_aux.parameters(), lr=0.00001, momentum=0.95)  \n",
    "test_results_aux = multiple_training_runs(model_aux, nb_runs, optimizer_aux, train_input, train_target, train_classes, \n",
    "                                          test_input, test_target, test_classes, mini_batch_size, nb_epochs)\n",
    "write_to_csv('auxiliary_losses.csv', model_aux, test_results_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(160.96547901630402, 8.627074330809831, 0.6915, 0.002121320343559723)\n",
      "Overwriting file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Number of parameters</th>\n",
       "      <th>Training time</th>\n",
       "      <th>Mean accuracy (test set)</th>\n",
       "      <th>Std accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Incept1</td>\n",
       "      <td>175027</td>\n",
       "      <td>160.97</td>\n",
       "      <td>0.6915</td>\n",
       "      <td>0.0021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Number of parameters  Training time  Mean accuracy (test set)  \\\n",
       "0  Incept1                175027         160.97                    0.6915   \n",
       "\n",
       "   Std accuracy  \n",
       "0        0.0021  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(test_results_aux)\n",
    "write_to_csv('auxiliary_losses.csv', model_aux, test_results_aux)\n",
    "data = pd.read_csv('auxiliary_losses.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight Sharing Model (Youssef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 2, 14, 14]) torch.Size([1000]) torch.Size([1000, 2]) torch.Size([1000, 2, 14, 14]) torch.Size([1000]) torch.Size([1000, 2])\n"
     ]
    }
   ],
   "source": [
    "print(train_input.shape, train_target.shape, train_classes.shape, test_input.shape, test_target.shape, test_classes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "from WSharingModel import *\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize it\n",
    "mean, std = train_input.mean(), train_input.std() \n",
    "train_input.sub_(mean).div_(std)\n",
    "test_input.sub_(mean).div_(std)\n",
    "train_input_Net3 = train_input.view(-1, 1, 14, 14)\n",
    "train_target_Net3 = train_classes.flatten()\n",
    "train_input, train_target, train_classes = Variable(train_input), Variable(train_target), Variable(train_classes)\n",
    "test_input, test_target = Variable(test_input), Variable(test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6668369174003601\n",
      "0.6389387249946594\n",
      "0.5997783541679382\n",
      "0.5608848929405212\n",
      "0.47221630811691284\n",
      "0.43288353085517883\n",
      "0.41329720616340637\n",
      "0.3842991888523102\n",
      "0.35745057463645935\n",
      "0.32919201254844666\n",
      "0.2964293956756592\n",
      "0.3015657365322113\n",
      "0.257221519947052\n",
      "0.24459552764892578\n",
      "0.24022550880908966\n",
      "0.22103363275527954\n",
      "0.20277614891529083\n",
      "0.18759697675704956\n",
      "0.2066190391778946\n",
      "0.16215385496616364\n",
      "0.1551346778869629\n",
      "0.13588294386863708\n",
      "0.13199284672737122\n",
      "0.11133017390966415\n",
      "0.15101686120033264\n",
      "model:   NetSharing1, criterion: CrossEntropyLoss, optimizer:        SGD, learning rate:    0.1, num epochs:  25, mini batch size: 100, training time:  8.00, train error:  4.00%, test error: 16.20%\n",
      "0.06339611858129501\n",
      "0.06098883971571922\n",
      "0.06073635071516037\n",
      "0.060218919068574905\n",
      "0.059233374893665314\n",
      "0.05807508900761604\n",
      "0.057028498500585556\n",
      "0.05593902990221977\n",
      "0.05480261147022247\n",
      "0.053654905408620834\n",
      "0.052507515996694565\n",
      "0.05141366645693779\n",
      "0.05030186101794243\n",
      "0.04922853410243988\n",
      "0.048247165977954865\n",
      "0.04726044833660126\n",
      "0.04634387418627739\n",
      "0.04540294036269188\n",
      "0.04451761767268181\n",
      "0.043625399470329285\n",
      "0.04275559261441231\n",
      "0.041916221380233765\n",
      "0.04109327495098114\n",
      "0.040269702672958374\n",
      "0.0394757054746151\n",
      "model:   NetSharing1, criterion: CrossEntropyLoss, optimizer:        SGD, learning rate:   0.01, num epochs:  25, mini batch size: 100, training time:  8.00, train error:  0.10%, test error: 13.90%\n",
      "0.03701286390423775\n",
      "0.037043698132038116\n",
      "0.03705989196896553\n",
      "0.037063926458358765\n",
      "0.037055984139442444\n",
      "0.03703847527503967\n",
      "0.037013255059719086\n",
      "0.03698151186108589\n",
      "0.03694392368197441\n",
      "0.03690200671553612\n",
      "0.03685452789068222\n",
      "0.03680433705449104\n",
      "0.036752767860889435\n",
      "0.03669746220111847\n",
      "0.03664250299334526\n",
      "0.03658333420753479\n",
      "0.036525823175907135\n",
      "0.036464910954236984\n",
      "0.036406584084033966\n",
      "0.036343954503536224\n",
      "0.03628307208418846\n",
      "0.036221589893102646\n",
      "0.03615777567028999\n",
      "0.036096442490816116\n",
      "0.03603244572877884\n",
      "model:   NetSharing1, criterion: CrossEntropyLoss, optimizer:        SGD, learning rate:  0.001, num epochs:  25, mini batch size: 100, training time:  8.00, train error:  0.10%, test error: 14.30%\n"
     ]
    }
   ],
   "source": [
    "    NB_EPOCHS = 25\n",
    "    MINI_BATCH_SIZE = 100\n",
    "    model = NetSharing1()\n",
    "    #models = [NetAuxiliary1]\n",
    "    optimizers = [optim.SGD]\n",
    "    learning_rates = [1e-1, 1e-2, 1e-3]\n",
    "    for optimizer in optimizers:\n",
    "            for learning_rate in learning_rates:\n",
    "               \n",
    "                training_time = train_model(model, optimizer(model.parameters(), lr=learning_rate), NB_EPOCHS, \\\n",
    "                        train_input, train_target, MINI_BATCH_SIZE)\n",
    " \n",
    "                print('model: {:>13}, criterion: {:>10}, optimizer: {:>10}, learning rate: {:6}, num epochs: {:3}, '\n",
    "                    'mini batch size: {:3}, training time: {:5.2f}, train error: {:5.2f}%, test error: {:5.2f}%'.format(\n",
    "                    model.__class__.__name__,\n",
    "                    model.criterion.__class__.__name__,\n",
    "                    optimizer.__name__,\n",
    "                    learning_rate,\n",
    "                    NB_EPOCHS,\n",
    "                    MINI_BATCH_SIZE,\n",
    "                    training_time,\n",
    "                    compute_nb_errors(model, train_input, train_target, MINI_BATCH_SIZE) / train_input.size(0) * 100,\n",
    "                    compute_nb_errors(model, test_input, test_target, MINI_BATCH_SIZE) / test_input.size(0) * 100\n",
    "                    )\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
